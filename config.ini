[general]
use_quantization=True
use_lora=True

[paths]
dataset_loader_folder=go_emo

[data_config]
personalized=True
instruct=True
data_folder=data/goemotions/personalized
train_filename=train.csv
val_filename=val.csv
test_filename=test.csv

[base_model_config]
base_model_name=stabilityai/stablelm-tuned-alpha-3b
max_seq_length=4096
problem_type=multi_label_classification

[training_config]
output_dir=checkpoints_stablelm-tuned-alpha-3b
per_device_train_batch_size=8
gradient_accumulation_steps=4
optim=paged_adamw_32bit
logging_steps=50
learning_rate=1e-4
fp16=True
max_grad_norm=1.0
num_train_epochs=5
evaluation_strategy=steps
eval_steps=0.03
warmup_ratio=0.05
group_by_length=True
save_safetensors=True
load_best_model_at_end=True
save_strategy=steps
save_steps=0.03
lr_scheduler_type=cosine
seed=42
report_to=wandb

[quantization_config]
load_in_4bit=True
bnb_4bit_use_double_quant=True
bnb_4bit_quant_type=nf4
bnb_4bit_compute_dtype=torch.bfloat16

[lora_config]
r=2
lora_alpha=32
lora_dropout=0.05
bias=none
task_type=SEQ_CLS
target_modules=all
